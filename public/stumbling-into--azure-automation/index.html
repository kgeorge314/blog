<!DOCTYPE html>
<html lang="en-gb">
    <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.30" />
    <title>Stumbling into … Azure Automation</title>
    
    
    
	  <meta property="og:title" content="Stumbling into … Azure Automation" />
<meta property="og:description" content="I&#8217;ve recently been trying to solve the challenge of working extracting files from AWS and getting them into Azure in my desired format. I wanted a solution that kept everything on the cloud and completely avoid local tin. I wanted it to have built-in auditing and error handling. I wanted something whizzy and new, to be honest! One way in which I attempted to tackle the task was with Azure Automation. In this post, I&#8217;ll overview Automation and explore how it stacked up for what I was attempting to use it for.


Overall Task: Get compressed (.tar.gz) files from AWS S3 to Azure, decompress the files, concatenate the contents and put in a different container for analytics magic


Like with most things I dropped myself into the deep-end on it so had fairly minimal knowledge of PowerShell and the Azure modules, therefore I fully expect more knowledgeable folks to wince at my stuff. General advice, &#8220;you should do it like this, then this&#8230;&#8221;&#8216;s, and resource recommendations are all very welcome &#8211; leave a comment with them in!

Azure Automation

Azure Automation is essentially a hosted PowerShell script execution service. It seems to be aimed primarily at managing Azure resources, particularly via Desired State Configurations.

It is, however, a general PowerShell powerhouse, with scheduling capabilities and a bunch of useful features for the safe storage of credentials etc. This makes it an excellent tool if you&#8217;re looking to do something with PowerShell on a regular basis and need to interact with Azure.

" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://itsalocke.com/blog/stumbling-into--azure-automation/" />



<meta property="article:published_time" content="2016-07-11T09:46:12&#43;00:00"/>

<meta property="article:modified_time" content="2016-07-11T09:46:12&#43;00:00"/>













<meta itemprop="name" content="Stumbling into … Azure Automation">
<meta itemprop="description" content="I&#8217;ve recently been trying to solve the challenge of working extracting files from AWS and getting them into Azure in my desired format. I wanted a solution that kept everything on the cloud and completely avoid local tin. I wanted it to have built-in auditing and error handling. I wanted something whizzy and new, to be honest! One way in which I attempted to tackle the task was with Azure Automation. In this post, I&#8217;ll overview Automation and explore how it stacked up for what I was attempting to use it for.


Overall Task: Get compressed (.tar.gz) files from AWS S3 to Azure, decompress the files, concatenate the contents and put in a different container for analytics magic


Like with most things I dropped myself into the deep-end on it so had fairly minimal knowledge of PowerShell and the Azure modules, therefore I fully expect more knowledgeable folks to wince at my stuff. General advice, &#8220;you should do it like this, then this&#8230;&#8221;&#8216;s, and resource recommendations are all very welcome &#8211; leave a comment with them in!

Azure Automation

Azure Automation is essentially a hosted PowerShell script execution service. It seems to be aimed primarily at managing Azure resources, particularly via Desired State Configurations.

It is, however, a general PowerShell powerhouse, with scheduling capabilities and a bunch of useful features for the safe storage of credentials etc. This makes it an excellent tool if you&#8217;re looking to do something with PowerShell on a regular basis and need to interact with Azure.

">


<meta itemprop="datePublished" content="2016-07-11T09:46:12&#43;00:00" />
<meta itemprop="dateModified" content="2016-07-11T09:46:12&#43;00:00" />
<meta itemprop="wordCount" content="620">



<meta itemprop="keywords" content="aws,azure,azure automation,etl,failures,powershell," />

<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Stumbling into … Azure Automation"/>
<meta name="twitter:description" content="I&#8217;ve recently been trying to solve the challenge of working extracting files from AWS and getting them into Azure in my desired format. I wanted a solution that kept everything on the cloud and completely avoid local tin. I wanted it to have built-in auditing and error handling. I wanted something whizzy and new, to be honest! One way in which I attempted to tackle the task was with Azure Automation. In this post, I&#8217;ll overview Automation and explore how it stacked up for what I was attempting to use it for.


Overall Task: Get compressed (.tar.gz) files from AWS S3 to Azure, decompress the files, concatenate the contents and put in a different container for analytics magic


Like with most things I dropped myself into the deep-end on it so had fairly minimal knowledge of PowerShell and the Azure modules, therefore I fully expect more knowledgeable folks to wince at my stuff. General advice, &#8220;you should do it like this, then this&#8230;&#8221;&#8216;s, and resource recommendations are all very welcome &#8211; leave a comment with them in!

Azure Automation

Azure Automation is essentially a hosted PowerShell script execution service. It seems to be aimed primarily at managing Azure resources, particularly via Desired State Configurations.

It is, however, a general PowerShell powerhouse, with scheduling capabilities and a bunch of useful features for the safe storage of credentials etc. This makes it an excellent tool if you&#8217;re looking to do something with PowerShell on a regular basis and need to interact with Azure.

"/>
<meta name="twitter:site" content="@lockedata"/>

    <meta name="description" content="Locke Data helps organisations get started with data science. Grow your skills with our blog posts." />
    <meta name="keywords" content='aws,azure,azure automation,etl,failures,powershell' />
    
        <meta name="author" content="Steph" />
    
    
	
    <link rel="stylesheet" href="https://itsalocke.com/blog/css/bootstrap.min.css" />
    <link rel="stylesheet" href="https://itsalocke.com/blog/css/highlightjs-themes/androidstudio.css" />
    <link rel="stylesheet" href="https://itsalocke.com/blog/css/font-awesome.min.css" />
    <link rel="stylesheet" href="https://itsalocke.com/blog/css/lockedata.css" />
    
        
            <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
            <script>
                (adsbygoogle = window.adsbygoogle || []).push({
                    google_ad_client: "ca-pub-XXXXXX",
                    enable_page_level_ads: true
                });
            </script>
        
    
</head>

    <body>
        <!-- Navigation -->
<nav class="navbar navbar-default navbar-fixed-top">
  <div class="container">

    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header page-scroll">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
        <span class="sr-only"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
        <a class="navbar-brand page-scroll" href="/blog/#page-top">
          
          <img src="https://itsalocke.com/blog/img/LockeDataTextNew.svg" class="img-responsive" alt="">
        </a>
      

    </div>
    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav navbar-right">
        <li class="hidden">
          <a href="/blog/#page-top"></a>
        </li>
        
          <li>
            <a href="https://itsalocke.com">Locke Data</a>
          </li>
        
          <li>
            <a href="https://itsalocke.com/blog/">Blog</a>
          </li>
        

        
        
      </ul>
    </div>
    <!-- /.navbar-collapse -->
  </div>
  <!-- /.container-fluid -->
</nav>

        <div id="top" class="container">
            <div class="row" id="content-main">
                    <div class="row">
    <div class="col-md-12 content-card">
        <h1>Stumbling into … Azure Automation</h1>
        
            
            <ul class="list-inline meta">
                <li><i class="fa fa-calendar"></i>July 11, 2016</li>
                <li><i class="fa fa-user"></i>Steph</li>
                
                    
                    <li><i class="fa fa-folder"></i><a href="https://itsalocke.com/categories/dataops">DataOps</a>, <a href="https://itsalocke.com/categories/microsoft-data-platform">Microsoft Data Platform</a></li>
                
            </ul>
        
        
    <ul class="list-inline tags" style="margin-top: 15px; margin-left: 0px">
        
            <li style=""><a href="https://itsalocke.com/tags/aws">aws</a></li>
        
            <li style=""><a href="https://itsalocke.com/tags/azure">azure</a></li>
        
            <li style=""><a href="https://itsalocke.com/tags/azure-automation">azure automation</a></li>
        
            <li style=""><a href="https://itsalocke.com/tags/etl">etl</a></li>
        
            <li style=""><a href="https://itsalocke.com/tags/failures">failures</a></li>
        
            <li style=""><a href="https://itsalocke.com/tags/powershell">powershell</a></li>
        
    </ul>


        <p>I&#8217;ve recently been trying to solve the challenge of working extracting files from AWS and getting them into Azure in my desired format. I wanted a solution that kept everything on the cloud and completely avoid local tin. I wanted it to have built-in auditing and error handling. I wanted something whizzy and new, to be honest! One way in which I attempted to tackle the task was with <a href="https://azure.microsoft.com/en-gb/services/automation/">Azure Automation</a>. In this post, I&#8217;ll overview Automation and explore how it stacked up for what I was attempting to use it for.</p>

<blockquote>
<p>Overall Task: Get compressed (.tar.gz) files from AWS S3 to Azure, decompress the files, concatenate the contents and put in a different container for analytics magic</p>
</blockquote>

<p>Like with most things I dropped myself into the deep-end on it so had fairly minimal knowledge of PowerShell and the Azure modules, therefore I fully expect more knowledgeable folks to wince at my stuff. General advice, &#8220;you should do it like this, then this&#8230;&#8221;&#8216;s, and resource recommendations are all very welcome &#8211; leave a comment with them in!</p>

<h2 id="azure-automation">Azure Automation</h2>

<p>Azure Automation is essentially a hosted PowerShell script execution service. It seems to be aimed primarily at managing Azure resources, particularly via <a href="https://www.simple-talk.com/sysadmin/powershell/powershell-desired-state-configuration-the-basics/">Desired State Configurations</a>.</p>

<p>It is, however, a general PowerShell powerhouse, with scheduling capabilities and a bunch of useful features for the safe storage of credentials etc. This makes it an excellent tool if you&#8217;re looking to do something with PowerShell on a regular basis and need to interact with Azure.</p>

<p></p>

<h2 id="bits-i-used">Bits I used</h2>

<h3 id="assets">Assets</h3>

<p>The <a href="https://azure.microsoft.com/en-gb/blog/getting-started-with-azure-automation-automation-assets-2/">assets</a> aspect of Automation I really loved. This section of functionality allows you to securely store values like API keys and credentials, and also contains schedules and modules but I&#8217;ll cover those separately.</p>

<p>Securely stored values can be retrieved by an Automation job and can continue being passed through the workflow in a secure fashion. This is pretty awesome!</p>

<p>In:</p>

<pre><code>$rgname = &quot;rg&quot;
$automation = &quot;posh&quot;

if((Get-AzureAccount).Count -lt 1) {Login-AzureRmAccount}

New-AzureRmAutomationVariable –Name 'aws_accountkey' –Value 'blah' –Encrypted $false  –AutomationAccountName $automation  -ResourceGroupName $rgname
</code></pre>

<p>Out:</p>

<pre><code># Your account access key - must have read access to your S3 Bucket
$accessKey = (Get-AzureRMAutomationVariable -Name 'aws_accountkey' -ResourceGroupName $rgname -AutomationAccountName $automationaccount ).Value
</code></pre>

<h3 id="modules">Modules</h3>

<p><img src="../img/modules_phd06a.png" alt="Azure Automation Modules facility" width="300" height="120" class="alignleft size-medium wp-image-61693" /></p>

<p>To be able to work with S3 files, I needed a specific PoweShell module. You are able to add modules easily within the GUI. The nifty thing is you can import modules from the <a href="https://www.powershellgallery.com/">PowerShell Gallery</a>, so I was able to use the <a href="https://www.powershellgallery.com/packages/AWSPowerShell">AWSPowerShell</a> module within my runbook.</p>

<h3 id="local-dev">Local dev</h3>

<p><img src="../img/automationise_z543r6.png" alt="PowerShell Automation ISE" width="175" height="300" class="alignright size-medium wp-image-61692" /></p>

<p>Uploading scripts and running them in just hoping they worked would be a poor development experience. Thankfully, there is an awesome addition to the PowerShell ISE that you can get via the PowerShell Gallery called the <a href="https://www.powershellgallery.com/packages/AzureAutomationAuthoringToolkit/0.2.3.4">Azure Automation Authoring Toolkit</a>. This enables you to make variables, make local versions of them, draft and publish runbooks. It&#8217;s a vital piece of tech for building Azure Automation runbooks.</p>

<h2 id="problems-encountered">Problems encountered</h2>

<ul>
<li>Not a lot of Azure Automation docs use the <a href="https://azure.microsoft.com/en-gb/documentation/articles/resource-group-overview/">Azure Resource Manager</a> PoSh cmdlets, this made it tough sometimes to know what to do</li>
<li>I couldn&#8217;t find a purely PowerShell solution for decompressing tar.gz files and the use of an exe like 7zip seemed difficult to achieve</li>
</ul>

<h2 id="wrap-up">Wrap up</h2>

<p>In the end, I was only able to get the latest files from s3 and dump them into blob storage. I didn&#8217;t succeed at my goal but I was very impressed with Azure Automation and fully intend on using it in future. You can see an example of what I wrote for this task as a <a href="https://gist.github.com/stephlocke/410ad30ca863ea5388b5a3fd2d2b1be8">gist</a>.</p>

<p>Thanks for reading and tips on improving the code or achieving the decompression of .tar.gz files will be gratefully received. If you haven&#8217;t used Automation yet, I recommend you give it a try.</p>
		</div>
		
</div>
    <div class="row">
    <div class="col-md-12 card">
        <h5>Search</h5>
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form">
            <div class="input-group">
                <input class="form-control" type="search" name="q" />
                <span class="input-group-btn">
                    <button class="btn btn-primary" type="submit"><span class="glyphicon glyphicon-search"></span></button>
                </span>
            </div>
            <input type="hidden" name="q" value="site:https://itsalocke.com/blog/">
        </form>
    </div>
</div>

<div class="row">
		  <div class="col-md-12 content-card">
        
    <ul class="list-inline share" style="margin-top: 15px; margin-left: 0px">
        <li class="facebook-share"><a target="_blank" href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fitsalocke.com%2fblog%2fstumbling-into--azure-automation%2f"><i class="fa fa-facebook fa-lg"></i>Facebook</a></li>
        <li class="googleplus-share"><a target="_blank" href="https://plus.google.com/share?url=https%3a%2f%2fitsalocke.com%2fblog%2fstumbling-into--azure-automation%2f"><i class="fa fa-google-plus fa-lg"></i>Google+</a></li>
        <li class="twitter-share"><a target="_blank" href="https://twitter.com/share?url=https%3a%2f%2fitsalocke.com%2fblog%2fstumbling-into--azure-automation%2f&amp;text=Stumbling%20into%20%e2%80%a6%20Azure%20Automation"><i class="fa fa-twitter fa-lg"></i>Twitter</a></li>
        <li class="reddit-share"><a target="_blank" href="http://reddit.com/submit?url=https%3a%2f%2fitsalocke.com%2fblog%2fstumbling-into--azure-automation%2f&amp;title=Stumbling%20into%20%e2%80%a6%20Azure%20Automation"><i class="fa fa-reddit fa-lg"></i>Reddit</a></li>
        <li class="linkedin-share"><a target="_blank" href="http://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fitsalocke.com%2fblog%2fstumbling-into--azure-automation%2f"><i class="fa fa-linkedin fa-lg"></i>LinkedIn</a></li>
        <li class="stumbleupon-share"><a target="_blank" href="http://www.stumbleupon.com/submit?url=https%3a%2f%2fitsalocke.com%2fblog%2fstumbling-into--azure-automation%2f&amp;title=Stumbling%20into%20%e2%80%a6%20Azure%20Automation"><i class="fa fa-stumbleupon fa-lg"></i>StumbleUpon</a></li>
    </ul>


    </div>
	</div>

                    
    
        <div class="row">
            <div class="col-md-12 content-card">
                <div id="disqus_thread"></div>
                <script>
                    (function() {
                        if (window.location.hostname == "localhost") {
                            document.write("Disqus comments are unavailable while serving on localhost or 127.0.0.1");
                            return;
                        }
                        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                        var disqus_shortname = 'itsalocke';
                        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                    })();
                </script>
                <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
            </div>
        </div>
    


            </div>
        </div>
        <!-- Footer section -->
<footer>
  <div class="container">
    <div class="row">
      <div class="col-md-4">
        <span class="copyright">
          <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
        </span>
      </div>
      <div class="col-md-4">
        <ul class="list-inline social-buttons">
          
            <li>
              <a href="https://twitter.com/lockedata"><i class='fa fa-twitter'></i></a>
            </li>
          
            <li>
              <a href="https://facebook.com/lockedata"><i class='fa fa-facebook'></i></a>
            </li>
          
            <li>
              <a href="https://linkedin.com/company/locke-data"><i class='fa fa-linkedin'></i></a>
            </li>
          
            <li>
              <a href="https://github.com/lockedata"><i class='fa fa-github'></i></a>
            </li>
          
        </ul>
      </div>
      <div class="col-md-4">
        <ul class="list-inline quicklinks">
          
            <li>
              <a href="/blog/index.xml">RSS</a>
            </li>
          
            <li>
              <a href="https://itsalocke.com/company/policies">Legalese and stuff</a>
            </li>
          
            <li>
              <a href="https://goo.gl/forms/KQiYR201Fcn4k9Zh2">Bug Bounty</a>
            </li>
          
        </ul>
      </div>
    </div>
  </div>
</footer>

        <div id="back-to-top" class="hidden">
    <a href="#top" class="well well-sm" onclick="$('html,body').animate({scrollTop:0},'slow');return false;">
        <i class="glyphicon glyphicon-chevron-up"></i> Back to Top
    </a>
</div>
<script src="https://itsalocke.com/blog/js/jquery.min.js"></script>
<script src="https://itsalocke.com/blog/js/bootstrap.min.js"></script>
<script src="https://itsalocke.com/blog/js/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>
    if(($(window).height() + 100) < $(document).height()) {
        $('#back-to-top').removeClass('hidden').affix({
            offset: {
                top: 100
            }
        });
    }
</script>

    
        <script>
            
            [].forEach.call(document.querySelectorAll('.adsbygoogle'), function() {
                (adsbygoogle = window.adsbygoogle || []).push({});
            });
        </script>
    


    
 
 
 <script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-58415537-1', 'auto');


ga('require', 'eventTracker');
ga('require', 'outboundLinkTracker');
ga('require', 'urlChangeTracker');
ga('require', 'cleanUrlTracker');
ga('require', 'impressionTracker');
ga('require', 'maxScrollTracker');
ga('require', 'pageVisibilityTracker');


ga('send', 'pageview');
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
<script async src="js/autotrack.js"></script>




    </body>
</html>
